{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e32b56e-e65d-41c3-b527-c7ad1573c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing GC perturbation to Alu and Alu-flanking sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2aefff-97d0-4e71-8966-6754a57a9105",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f90f94a-7223-46c8-a43b-b17bdb07afd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import basenji\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os, psutil, io, gzip, time \n",
    "import pysam\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pybedtools import BedTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef87c230-ab6b-4310-be00-05500e60329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce54f097-cf1d-41a8-bff9-10d1ea4de9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vcf_gz(path):\n",
    "    \n",
    "    '''\n",
    "    Read  gzipped vcf files into dataframe.\n",
    "    Adapted from: https://gist.github.com/dceoy/99d976a2c01e7f0ba1c813778f9db744.\n",
    "    \n",
    "    '''    \n",
    "    with io.TextIOWrapper(gzip.open(path,'r')) as f:\n",
    "        lines =[l for l in f if not l.startswith('#')]        \n",
    "    vcf_file = io.StringIO(''.join(lines))\n",
    "    \n",
    "    return vcf_file\n",
    "\n",
    "def calculate_gc(chrom, start, end):\n",
    "    seq = hg38_fa.fetch(chrom, start, end).upper()\n",
    "    gc_count = seq.count('G') + seq.count('C')\n",
    "    return (gc_count / len(seq)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0d4522-bcbc-4fbc-b7de-defc81e1de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "hg38_file = '/pollard/home/shzhang/akita/run_akita/refs/hg38.fa'\n",
    "hg38_fa = pysam.Fastafile(hg38_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a375958-3c92-4b23-848a-92a6b2dc8fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "alu_data_dir='/pollard/home/shzhang/alu/data/'\n",
    "os.listdir(alu_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe31909-ff44-4ff6-b4c4-6ad2c54e3309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7485e9ba-ae2a-4b45-86c6-7f1ad6316436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44519908-4cec-441a-8d76-527cb04f7eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "in_file = ''\n",
    "input_sequences = None\n",
    "fasta_path = hg38_file\n",
    "genome = 'hg38'\n",
    "scores_to_use = ['mse', 'corr']\n",
    "shift_by = [-1, 0, 1]\n",
    "out_file = '20240116_test'\n",
    "out_dir = '/pollard/home/shzhang/alu_supremo/test_out/'\n",
    "seq_len = 1048576\n",
    "\n",
    "revcomp = 'add_revcomp'\n",
    "augment = True\n",
    "get_seq = True\n",
    "get_tracks = False\n",
    "get_maps = False\n",
    "get_Akita_scores = True\n",
    "var_set_size = 0\n",
    "svlen_limit=700e3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61cd628-dae1-4dff-b881-c4bbe7c30a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "# Adjust inputs from arguments\n",
    "\n",
    "\n",
    "# Handle paths\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# This file path and repo path\n",
    "repo_path = '/pollard/home/shzhang/alu_supremo/'\n",
    "\n",
    "# Output directory and file\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "out_file = os.path.join(out_dir, out_file)\n",
    "\n",
    "\n",
    "# Data path\n",
    "chrom_lengths_path = f'{repo_path}/data/chrom_lengths_{genome}'\n",
    "centromere_coords_path = f'{repo_path}/data/centromere_coords_{genome}'\n",
    "   \n",
    "\n",
    "# Adjust shift input: Remove shifts that are outside of allowed range\n",
    "max_shift = 0.4*seq_len\n",
    "print(max_shift)\n",
    "shift_by = [x for x in shift_by if x > -max_shift and x < max_shift]\n",
    "\n",
    "\n",
    "# Adjust input for taking the reverse complement\n",
    "if revcomp == 'no_revcomp':\n",
    "    revcomp_decision = [False]\n",
    "elif revcomp == 'add_revcomp':\n",
    "    revcomp_decision = [False, True]\n",
    "elif revcomp == 'only_revcomp':\n",
    "    revcomp_decision = [True]\n",
    "\n",
    "if augment and shift_by == [0] and revcomp == 'no_revcomp':\n",
    "    shift_by = [-1,0,1]\n",
    "    revcomp_decision = [False, True]\n",
    "\n",
    "revcomp_decision_i = revcomp_decision\n",
    "\n",
    "import pysam\n",
    "\n",
    "if input_sequences is not None:\n",
    "    seq_names = pysam.Fastafile(input_sequences).references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb88120f-ff91-4726-b7b6-4a3458062da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries to save sequences, maps, and disruption score tracks, if specified\n",
    "if get_seq:\n",
    "    sequences = {}\n",
    "    \n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "# Read in (and adjust) data\n",
    "\n",
    "\n",
    "chrom_lengths = pd.read_table(chrom_lengths_path, header = None, names = ['CHROM', 'chrom_max'])\n",
    "centromere_coords = pd.read_table(centromere_coords_path, sep = '\\t')\n",
    "fasta_open = pysam.Fastafile(fasta_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4f0726-f583-42ff-8f7b-1197c2b6eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /pollard/home/shzhang/alu_supremo/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f28382d-5df6-47fe-9ace-0874a737b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign necessary values to variables across module\n",
    "\n",
    "# Module 1: reading utilities\n",
    "import sys\n",
    "sys.path.insert(0, './scripts/')\n",
    "import reading_utils\n",
    "reading_utils.var_set_size = var_set_size\n",
    "\n",
    "\n",
    "# Module 2: get_seq utilities\n",
    "import get_seq_utils\n",
    "get_seq_utils.fasta_open = fasta_open\n",
    "get_seq_utils.chrom_lengths = chrom_lengths\n",
    "get_seq_utils.centromere_coords = centromere_coords\n",
    "\n",
    "get_seq_utils.svlen_limit = svlen_limit\n",
    "get_seq_utils.seq_length = seq_len\n",
    "get_seq_utils.half_patch_size = round(seq_len/2)\n",
    "\n",
    "\n",
    "# Module 2: get_Akita_scores utilities\n",
    "if get_Akita_scores:\n",
    "    import get_Akita_scores_utils\n",
    "    get_Akita_scores_utils.chrom_lengths = chrom_lengths\n",
    "    get_Akita_scores_utils.centromere_coords = centromere_coords\n",
    "    \n",
    "#module 3: seq-MUTATE_UTILS\n",
    "gc_mutate=True\n",
    "motif_mutate=False\n",
    "if gc_mutate or motif_mutate:\n",
    "    import seq_mutate_utils\n",
    "\n",
    "   \n",
    "    \n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "nt = ['A', 'T', 'C', 'G']\n",
    "    \n",
    "var_set = 0\n",
    "var_set_list = []\n",
    "\n",
    "print(f'Log file being saved here: {out_file}_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5b9ba1-1aae-4d78-ba40-2a1507da94c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants=alu_test\n",
    "variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354f3e93-c6b5-4fbc-93ed-5717ace2f28d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e70799-7070-44b6-bd3d-9e57bf6bda2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "    # Run: Make Akita predictions and calculate disruption scores\n",
    "\n",
    "\n",
    "\n",
    "nt = ['A', 'T', 'C', 'G']\n",
    "    \n",
    "var_set = 0\n",
    "var_set_list = []\n",
    "\n",
    "print(f'Log file being saved here: {out_file}_log')\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Read in variants\n",
    "    #variants = reading_utils.read_input(in_file, var_set)\n",
    "    if len(variants) == 0:\n",
    "        break\n",
    "        \n",
    "        \n",
    "    # Index input based on row number and create output with same indexes\n",
    "    variants['var_index'] = list(range(var_set*var_set_size, var_set*var_set_size + len(variants)))\n",
    "    variants['var_index'] = variants['var_index'].astype(str)\n",
    "\n",
    "    \n",
    "    # If there are multiple alternate alleles, split those into new rows and indexes\n",
    "    if any([',' in x for x in variants.ALT]):\n",
    "\n",
    "        variants = (variants\n",
    "                 .set_index(['CHROM', 'POS', 'REF', 'var_index'])\n",
    "                 .apply(lambda x: x.str.split(',').explode())\n",
    "                 .reset_index())\n",
    "\n",
    "        g = variants.groupby(['var_index'])\n",
    "        variants.loc[g['var_index'].transform('size').gt(1),\n",
    "               'var_index'] += '-'+g.cumcount().astype(str)\n",
    "        \n",
    "    variant_scores = pd.DataFrame({'var_index':variants.var_index})\n",
    "    \n",
    "  \n",
    "\n",
    "\n",
    "    # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "    # Filter out variants that cannot be scored\n",
    "\n",
    "    # Get indexes for variants to exclude\n",
    "\n",
    "    # Exclude mitochondrial variants\n",
    "    chrM_var = pd.DataFrame({'var_index' : list(variants[variants.CHROM == 'chrM'].var_index),\n",
    "                             'reason' : ' Mitochondrial chromosome.'})\n",
    "\n",
    "    # Exclude variants larger than limit\n",
    "    if 'SVLEN' in variants.columns:\n",
    "        too_long_var = pd.DataFrame({'var_index' : [y for x,y in zip(variants.SVLEN, variants.var_index) \n",
    "                                                    if not pd.isnull(x) and abs(int(x)) > svlen_limit],\n",
    "                                     'reason' : f' SV longer than {svlen_limit}.'})\n",
    "        unsuitable_var = pd.DataFrame({'var_index' : [y for x,y,z in zip(variants.SVTYPE, variants.var_index, variants.ALT) \n",
    "                                                      if not pd.isnull(x) and \n",
    "                                                      x not in [\"DEL\", \"DUP\", \"INV\", \"BND\"] and \n",
    "                                                      all([g not in nt for g in z])],\n",
    "                                       'reason' : ' SV type not compatible.'})\n",
    "    else:\n",
    "        too_long_var = pd.DataFrame()\n",
    "        unsuitable_var = pd.DataFrame()\n",
    "\n",
    "    filtered_out = pd.concat([chrM_var, too_long_var], axis = 0)\n",
    "    filtered_out = pd.concat([filtered_out, unsuitable_var], axis = 0)\n",
    "    filtered_out.var_index = filtered_out.var_index.astype('str')\n",
    "\n",
    "    # Save filtered out variants into file\n",
    "    filtered_out.to_csv(f'{out_file}_filtered_out_{var_set}', sep = ':', index = False, header = False)\n",
    "\n",
    "    # Exclude\n",
    "    variants = variants[[x not in filtered_out.var_index.values for x in variants.var_index]]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Loop through each row (not index) and get disruption scores \n",
    "    for i in range(len(variants))[0:2]:\n",
    "        print('i', i)\n",
    "\n",
    "        variant = variants.iloc[i]\n",
    "\n",
    "        var_index = variant.var_index\n",
    "        CHR = variant.CHROM\n",
    "        POS = variant.POS\n",
    "        REF = variant.REF\n",
    "        ALT = variant.ALT\n",
    "            \n",
    "\n",
    "        if 'SVTYPE' in variants.columns:\n",
    "            END = variant.END\n",
    "            SVTYPE = variant.SVTYPE\n",
    "            SVLEN = variant.SVLEN\n",
    "        else:\n",
    "            END = np.nan\n",
    "            SVTYPE = np.nan\n",
    "            SVLEN = 0\n",
    "\n",
    "        for shift in shift_by:\n",
    "            print('shift', shift)\n",
    "\n",
    "            # Take reverse complement only with 0 shift\n",
    "            if shift != 0 & True in revcomp_decision:\n",
    "                revcomp_decision_i = [False]\n",
    "            else:\n",
    "                revcomp_decision_i = revcomp_decision\n",
    "            #revcomp_decision is list of T/F\n",
    "            for revcomp in revcomp_decision_i:\n",
    "                print('revcomp', revcomp)\n",
    "\n",
    "                try:\n",
    "\n",
    "                    if revcomp:\n",
    "                        revcomp_annot = '_revcomp'\n",
    "                    else:\n",
    "                        revcomp_annot = ''\n",
    "\n",
    "                    print('input_sequences', input_sequences)\n",
    "                    if input_sequences is not None:\n",
    "\n",
    "                        # Generate sequences_i from sequence input\n",
    "                        if revcomp_annot == '':\n",
    "                            sequence_names = [x for x in seq_names if x.startswith(f'{var_index}_{shift}') and \n",
    "                                              'revcomp' not in x]\n",
    "                        elif revcomp_annot == '_revcomp':\n",
    "                            sequence_names = [x for x in seq_names if x.startswith(f'{var_index}_{shift}{revcomp_annot}')]\n",
    "\n",
    "                        sequences_i = []\n",
    "                        print('sequence_names', sequence_names)\n",
    "                        for sequence_name in sequence_names:\n",
    "                            sequences_i.append(pysam.Fastafile(input_sequences).fetch(sequence_name, 0, seq_len).upper())\n",
    "\n",
    "                        sequences_i.append([int(x) for x in sequence_name.split('[')[1].split(']')[0].split('_')])\n",
    "                        \n",
    "\n",
    "                    else:\n",
    "\n",
    "                        # Create sequences_i from variant input\n",
    "                        #get_sequences_SV (for non-BND) returns:\n",
    "                        #REF_seq, ALT_seq, [var_rel_pos_REF, var_rel_pos_ALT]\n",
    "                        #var_rel_pos_REF is variant position relative to the reference sequence \n",
    "                        #(relative position of POS, or start of varianat)\n",
    "                        #var_rel_pos_ALT is variant position relative to reference still? \n",
    "                        sequences_i = get_seq_utils.get_sequences_SV(CHR, POS, REF, ALT, END, SVTYPE, shift, revcomp)\n",
    "                        #print('sequences')\n",
    "                        #print(len(sequences_i))\n",
    "\n",
    "                    if get_seq:\n",
    "\n",
    "                        # Get relative position of variant in sequence\n",
    "                        var_rel_pos = str(sequences_i[-1]).replace(', ', '_')\n",
    "                        print('var rel pos', var_rel_pos)\n",
    "\n",
    "                        for ii in range(len(sequences_i[:-1][:3])): \n",
    "                            sequences[f'{var_index}_{shift}{revcomp_annot}_{ii}_{var_rel_pos}'] = sequences_i[:-1][ii]\n",
    "                        #print('sequences i')\n",
    "                        #print(sequences_i)      \n",
    "                    #shu edit here\n",
    "                    #insert options post sequence whatever \n",
    "                    \n",
    "                    if gc_mutate:\n",
    "                        #we want to alter ref_seq in sequences_i\n",
    "                        #mutate_gc(seq, variant_start, variant_end, posflank, endflank, revcomp, mut_percent):\n",
    "                        var_rel_pos=sequences_i[-1][0]\n",
    "                        new_seq=seq_mutate_utils.mutate_gc(sequences_i[0], var_rel_pos, var_rel_pos+SVLEN, \n",
    "                                                           0,0, revcomp, 50)\n",
    "                        \n",
    "                        #for now, replace the alt seq with the gc mutated seq\n",
    "                        sequences_i_list=list(sequences_i)\n",
    "                        sequences_i_list[1]=new_seq\n",
    "                        sequences_i=tuple(sequences_i_list)\n",
    "                        \n",
    "                        \n",
    "                    \n",
    "                    \n",
    "                    if motif_mutate:\n",
    "                        var_rel_pos=sequences_i[-1][0]\n",
    "                        new_seq=seq_mutate_utils.shuffle_nucs(sequences_i[0], var_rel_pos, var_rel_pos+SVLEN, \n",
    "                                                              posflank, endflank, revcomp)\n",
    "         \n",
    "                        \n",
    "                        #for now, replace the alt seq with the gc mutated seq\n",
    "                        sequences_i[1]=new_seq \n",
    "                            \n",
    "                    if get_Akita_scores:\n",
    "\n",
    "                        scores = get_Akita_scores_utils.get_scores(POS, SVTYPE, SVLEN, \n",
    "                                                                   sequences_i, scores_to_use, \n",
    "                                                                   shift, revcomp, \n",
    "                                                                   get_tracks, get_maps)\n",
    "                        \n",
    "                        print('akita scores')\n",
    "                        print(scores)\n",
    "\n",
    "\n",
    "                        if get_tracks:\n",
    "                            for track in [x for x in scores.keys() if 'track' in x]:\n",
    "                                variant_tracks[f'{var_index}_{track}_{shift}{revcomp_annot}'] = scores[track]\n",
    "                                del scores[track]\n",
    "\n",
    "                        if get_maps:\n",
    "                            variant_maps[f'{var_index}_{shift}{revcomp_annot}'] = scores['maps']\n",
    "                            del scores['maps']\n",
    "\n",
    "                        for score in scores:\n",
    "                            variant_scores.loc[variant_scores.var_index == var_index, \n",
    "                                               f'{score}_{shift}{revcomp_annot}'] = scores[score]\n",
    "\n",
    "\n",
    "                    print(str(var_index) + ' (' + str(shift) + f' shift{revcomp_annot})')\n",
    "\n",
    "                except Exception as e: \n",
    "\n",
    "                    print(str(var_index) + ' (' + str(shift) + f' shift{revcomp_annot})' + ': Error:', e)\n",
    "\n",
    "                    pass\n",
    " \n",
    "    \n",
    "      \n",
    "    # Write standard output with error messages and warnings to log file\n",
    "    #sys.stdout = std_output\n",
    "    #log_file.close()\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # Combine results from all sets\n",
    "\n",
    "\n",
    "    # Write sequences to fasta file\n",
    "    if get_seq:\n",
    "\n",
    "        if var_set == 0:\n",
    "            sequences_all = sequences.copy()\n",
    "        else:\n",
    "            sequences_all.update(sequences)\n",
    "\n",
    "#     # Write scores to data frame\n",
    "#     if get_Akita_scores:\n",
    "\n",
    "#         # Take average of augmented sequences\n",
    "#         if augment:\n",
    "#             for score in scores:\n",
    "#                 cols = [x for x in variant_scores.columns if score in x]\n",
    "#                 variant_scores[f'{score}_mean'] = variant_scores[cols].mean(axis = 1)\n",
    "#                 variant_scores[f'{score}_median'] = variant_scores[cols].median(axis = 1)\n",
    "#                 variant_scores.drop(cols, axis = 1, inplace = True)\n",
    "\n",
    "#         # Convert scores from float to string so you can merge scores for variants with multiple alleles\n",
    "#         for col in variant_scores.iloc[:,1:].columns:\n",
    "#             variant_scores[col] = [format(x, '.20f') for x in variant_scores[col]]\n",
    "            \n",
    "                \n",
    "#         # Join scores for alternate alleles, separated by a comma\n",
    "#         if any(['-' in x for x in variant_scores.var_index]):\n",
    "#             variant_scores['var_index'] = variant_scores.var_index.str.split('-').str[0]\n",
    "            \n",
    "#             variant_scores = (variant_scores\n",
    "#                               .set_index(['var_index'], drop = False)\n",
    "#                               .rename(columns = {'var_index':'var_index2'})\n",
    "#                               .groupby('var_index2')\n",
    "#                               .transform(','.join)\n",
    "#                               .reset_index()\n",
    "#                               .drop_duplicates())\n",
    "        \n",
    "#         if var_set == 0:\n",
    "#             variant_scores.to_csv(f'{out_file}_scores_{var_set}', sep = '\\t', index = False)\n",
    "#         else:\n",
    "#             variant_scores.to_csv(f'{out_file}_scores_{var_set}', sep = '\\t', index = False, header = False)\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    break\n",
    "        \n",
    "    var_set_list.append(var_set)\n",
    "    var_set += 1\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
