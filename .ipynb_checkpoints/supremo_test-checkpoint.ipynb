{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cf2f32e-ecb2-4c4d-985e-1f7c9602864d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 21:38:05.861051: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /home/ketringjoni/miniconda3/envs/supremo_akita_env/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "2024-03-21 21:38:06.734353: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-21 21:38:06.745460: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence (InputLayer)          [(None, 1048576, 4)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " stochastic_reverse_complement   ((None, 1048576, 4)  0          ['sequence[0][0]']               \n",
      " (StochasticReverseComplement)  , ())                                                             \n",
      "                                                                                                  \n",
      " stochastic_shift (StochasticSh  (None, 1048576, 4)  0           ['stochastic_reverse_complement[0\n",
      " ift)                                                            ][0]']                           \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 1048576, 4)   0           ['stochastic_shift[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1048576, 96)  4224        ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1048576, 96)  384        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 524288, 96)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 524288, 96)   0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 524288, 96)   46080       ['re_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 524288, 96)  384         ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 262144, 96)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 262144, 96)   0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 262144, 96)   46080       ['re_lu_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 262144, 96)  384         ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 131072, 96)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 131072, 96)   0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 131072, 96)   46080       ['re_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 131072, 96)  384         ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 65536, 96)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 65536, 96)    0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 65536, 96)    46080       ['re_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 65536, 96)   384         ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 32768, 96)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 32768, 96)    0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 32768, 96)    46080       ['re_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32768, 96)   384         ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 16384, 96)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 16384, 96)    0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 16384, 96)    46080       ['re_lu_6[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16384, 96)   384         ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 8192, 96)    0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 8192, 96)     0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 8192, 96)     46080       ['re_lu_7[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 8192, 96)    384         ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_7 (MaxPooling1D)  (None, 4096, 96)    0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 4096, 96)     0           ['max_pooling1d_7[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 4096, 96)     46080       ['re_lu_8[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 4096, 96)    384         ['conv1d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_8 (MaxPooling1D)  (None, 2048, 96)    0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)                 (None, 2048, 96)     0           ['max_pooling1d_8[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 2048, 96)     46080       ['re_lu_9[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 2048, 96)    384         ['conv1d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_9 (MaxPooling1D)  (None, 1024, 96)    0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)                (None, 1024, 96)     0           ['max_pooling1d_9[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 1024, 96)     46080       ['re_lu_10[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 1024, 96)    384         ['conv1d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_10 (MaxPooling1D  (None, 512, 96)     0           ['batch_normalization_10[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)                (None, 512, 96)      0           ['max_pooling1d_10[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 512, 48)      13824       ['re_lu_11[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 512, 48)     192         ['conv1d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)                (None, 512, 48)      0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 512, 96)      4608        ['re_lu_12[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 512, 96)     384         ['conv1d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512, 96)      0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 512, 96)      0           ['max_pooling1d_10[0][0]',       \n",
      "                                                                  'dropout[0][0]']                \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)                (None, 512, 96)      0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 512, 48)      13824       ['re_lu_13[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 512, 48)     192         ['conv1d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)                (None, 512, 48)      0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 512, 96)      4608        ['re_lu_14[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 512, 96)     384         ['conv1d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 512, 96)      0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 512, 96)      0           ['add[0][0]',                    \n",
      "                                                                  'dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_15 (ReLU)                (None, 512, 96)      0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 512, 48)      13824       ['re_lu_15[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 512, 48)     192         ['conv1d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_16 (ReLU)                (None, 512, 48)      0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 512, 96)      4608        ['re_lu_16[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 512, 96)     384         ['conv1d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 512, 96)      0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 512, 96)      0           ['add_1[0][0]',                  \n",
      "                                                                  'dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_17 (ReLU)                (None, 512, 96)      0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 512, 48)      13824       ['re_lu_17[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 512, 48)     192         ['conv1d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_18 (ReLU)                (None, 512, 48)      0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 512, 96)      4608        ['re_lu_18[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 512, 96)     384         ['conv1d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 512, 96)      0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 512, 96)      0           ['add_2[0][0]',                  \n",
      "                                                                  'dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_19 (ReLU)                (None, 512, 96)      0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 512, 48)      13824       ['re_lu_19[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 512, 48)     192         ['conv1d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_20 (ReLU)                (None, 512, 48)      0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 512, 96)      4608        ['re_lu_20[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 512, 96)     384         ['conv1d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 512, 96)      0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 512, 96)      0           ['add_3[0][0]',                  \n",
      "                                                                  'dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_21 (ReLU)                (None, 512, 96)      0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 512, 48)      13824       ['re_lu_21[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 512, 48)     192         ['conv1d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_22 (ReLU)                (None, 512, 48)      0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 512, 96)      4608        ['re_lu_22[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 512, 96)     384         ['conv1d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 512, 96)      0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 512, 96)      0           ['add_4[0][0]',                  \n",
      "                                                                  'dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_23 (ReLU)                (None, 512, 96)      0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 512, 48)      13824       ['re_lu_23[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 512, 48)     192         ['conv1d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)                (None, 512, 48)      0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)             (None, 512, 96)      4608        ['re_lu_24[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 512, 96)     384         ['conv1d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 512, 96)      0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 512, 96)      0           ['add_5[0][0]',                  \n",
      "                                                                  'dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_25 (ReLU)                (None, 512, 96)      0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)             (None, 512, 48)      13824       ['re_lu_25[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 512, 48)     192         ['conv1d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_26 (ReLU)                (None, 512, 48)      0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)             (None, 512, 96)      4608        ['re_lu_26[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 512, 96)     384         ['conv1d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 512, 96)      0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 512, 96)      0           ['add_6[0][0]',                  \n",
      "                                                                  'dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_27 (ReLU)                (None, 512, 96)      0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_27 (Conv1D)             (None, 512, 64)      30720       ['re_lu_27[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 512, 64)     256         ['conv1d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_28 (ReLU)                (None, 512, 64)      0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " one_to_two (OneToTwo)          (None, 512, 512, 64  0           ['re_lu_28[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concat_dist2d (ConcatDist2D)   (None, 512, 512, 65  0           ['one_to_two[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_29 (ReLU)                (None, 512, 512, 65  0           ['concat_dist2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 512, 512, 48  28080       ['re_lu_29[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 512, 512, 48  192        ['conv2d[0][0]']                 \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " symmetrize2d (Symmetrize2D)    (None, 512, 512, 48  0           ['batch_normalization_28[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_30 (ReLU)                (None, 512, 512, 48  0           ['symmetrize2d[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 512, 512, 24  10368       ['re_lu_30[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 512, 512, 24  96         ['conv2d_1[0][0]']               \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_31 (ReLU)                (None, 512, 512, 24  0           ['batch_normalization_29[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 512, 512, 48  1152        ['re_lu_31[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 512, 512, 48  192        ['conv2d_2[0][0]']               \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 512, 512, 48  0           ['batch_normalization_30[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 512, 512, 48  0           ['symmetrize2d[0][0]',           \n",
      "                                )                                 'dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " symmetrize2d_1 (Symmetrize2D)  (None, 512, 512, 48  0           ['add_8[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_32 (ReLU)                (None, 512, 512, 48  0           ['symmetrize2d_1[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 512, 512, 24  10368       ['re_lu_32[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 512, 512, 24  96         ['conv2d_3[0][0]']               \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_33 (ReLU)                (None, 512, 512, 24  0           ['batch_normalization_31[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 512, 512, 48  1152        ['re_lu_33[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 512, 512, 48  192        ['conv2d_4[0][0]']               \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 512, 512, 48  0           ['batch_normalization_32[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 512, 512, 48  0           ['symmetrize2d_1[0][0]',         \n",
      "                                )                                 'dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " symmetrize2d_2 (Symmetrize2D)  (None, 512, 512, 48  0           ['add_9[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_34 (ReLU)                (None, 512, 512, 48  0           ['symmetrize2d_2[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 512, 512, 24  10368       ['re_lu_34[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 512, 512, 24  96         ['conv2d_5[0][0]']               \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_35 (ReLU)                (None, 512, 512, 24  0           ['batch_normalization_33[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 512, 512, 48  1152        ['re_lu_35[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 512, 512, 48  192        ['conv2d_6[0][0]']               \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 512, 512, 48  0           ['batch_normalization_34[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 512, 512, 48  0           ['symmetrize2d_2[0][0]',         \n",
      "                                )                                 'dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " symmetrize2d_3 (Symmetrize2D)  (None, 512, 512, 48  0           ['add_10[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_36 (ReLU)                (None, 512, 512, 48  0           ['symmetrize2d_3[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 512, 512, 24  10368       ['re_lu_36[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 512, 512, 24  96         ['conv2d_7[0][0]']               \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_37 (ReLU)                (None, 512, 512, 24  0           ['batch_normalization_35[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 512, 512, 48  1152        ['re_lu_37[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 512, 512, 48  192        ['conv2d_8[0][0]']               \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 512, 512, 48  0           ['batch_normalization_36[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 512, 512, 48  0           ['symmetrize2d_3[0][0]',         \n",
      "                                )                                 'dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " symmetrize2d_4 (Symmetrize2D)  (None, 512, 512, 48  0           ['add_11[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_38 (ReLU)                (None, 512, 512, 48  0           ['symmetrize2d_4[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 512, 512, 24  10368       ['re_lu_38[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 512, 512, 24  96         ['conv2d_9[0][0]']               \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_39 (ReLU)                (None, 512, 512, 24  0           ['batch_normalization_37[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 512, 512, 48  1152        ['re_lu_39[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 512, 512, 48  192        ['conv2d_10[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 512, 512, 48  0           ['batch_normalization_38[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 512, 512, 48  0           ['symmetrize2d_4[0][0]',         \n",
      "                                )                                 'dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " symmetrize2d_5 (Symmetrize2D)  (None, 512, 512, 48  0           ['add_12[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_40 (ReLU)                (None, 512, 512, 48  0           ['symmetrize2d_5[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 512, 512, 24  10368       ['re_lu_40[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 512, 512, 24  96         ['conv2d_11[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_41 (ReLU)                (None, 512, 512, 24  0           ['batch_normalization_39[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 512, 512, 48  1152        ['re_lu_41[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 512, 512, 48  192        ['conv2d_12[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 512, 512, 48  0           ['batch_normalization_40[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 512, 512, 48  0           ['symmetrize2d_5[0][0]',         \n",
      "                                )                                 'dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " symmetrize2d_6 (Symmetrize2D)  (None, 512, 512, 48  0           ['add_13[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " cropping2d (Cropping2D)        (None, 448, 448, 48  0           ['symmetrize2d_6[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " upper_tri (UpperTri)           (None, 99681, 48)    0           ['cropping2d[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 99681, 5)     245         ['upper_tri[0][0]']              \n",
      "                                                                                                  \n",
      " switch_reverse_triu (SwitchRev  (None, 99681, 5)    0           ['dense[0][0]',                  \n",
      " erseTriu)                                                        'stochastic_reverse_complement[0\n",
      "                                                                 ][1]']                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 751,653\n",
      "Trainable params: 746,149\n",
      "Non-trainable params: 5,504\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "model_strides [2048]\n",
      "target_lengths [99681]\n",
      "target_crops [-49585]\n",
      "Akita successfully loaded\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('scripts/')\n",
    "\n",
    "import reading_utils\n",
    "import get_seq_utils\n",
    "import get_Akita_scores_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3447fe39-dc62-4aa2-b956-1bd0e9660f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d3da2f3-a188-42e5-a22a-1592e2139adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = 'test_data/test_set_edge_cases/test_set_edge_simple.bed'\n",
    "\n",
    "\n",
    "fasta_path = '/home/data/genomes/hg38.fa'\n",
    "genome = 'hg38'\n",
    "Akita_cell_types = ['HFF', 'H1hESC']\n",
    "scores_to_use = ['mse', 'corr']\n",
    "shift_by = [0]\n",
    "revcomp_decision = [False]\n",
    "revcomp_decision_i = revcomp_decision\n",
    "seq_len = 1048576\n",
    "svlen_limit = 2/3*seq_len\n",
    "\n",
    "repo_path = '~/SuPreMo'\n",
    "\n",
    "# Data path\n",
    "chrom_lengths_path = f'{repo_path}/data/chrom_lengths_{genome}'\n",
    "centromere_coords_path = f'{repo_path}/data/centromere_coords_{genome}'\n",
    "    \n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "# Read in (and adjust) data\n",
    "\n",
    "chrom_lengths = pd.read_table(chrom_lengths_path, header = None, names = ['CHROM', 'chrom_max'])\n",
    "centromere_coords = pd.read_table(centromere_coords_path, sep = '\\t')\n",
    "fasta_open = pysam.Fastafile(fasta_path)\n",
    "\n",
    "\n",
    "var_set = 0\n",
    "var_set_size = 1000\n",
    "\n",
    "reading_utils.var_set = var_set\n",
    "reading_utils.var_set_size = var_set_size\n",
    "\n",
    "get_seq_utils.fasta_open = fasta_open\n",
    "get_seq_utils.chrom_lengths = chrom_lengths\n",
    "get_seq_utils.centromere_coords = centromere_coords\n",
    "\n",
    "get_seq_utils.svlen_limit = svlen_limit\n",
    "get_seq_utils.seq_length = seq_len\n",
    "get_seq_utils.half_patch_size = round(seq_len/2)\n",
    "\n",
    "get_Akita_scores_utils.chrom_lengths = chrom_lengths\n",
    "get_Akita_scores_utils.centromere_coords = centromere_coords\n",
    "\n",
    "\n",
    "nt = ['A', 'T', 'C', 'G']\n",
    "    \n",
    "\n",
    "variants = reading_utils.read_input(in_file, var_set)\n",
    "\n",
    "\n",
    "# Index input based on row number and create output with same indexes\n",
    "variants['var_index'] = list(range(var_set*var_set_size, var_set*var_set_size + len(variants)))\n",
    "variants['var_index'] = variants['var_index'].astype(str)\n",
    "\n",
    "# If there are multiple alternate alleles, split those into new rows and indexes\n",
    "if any([',' in x for x in variants.ALT]):\n",
    "\n",
    "    variants = (variants\n",
    "             .set_index(['CHROM', 'POS', 'REF', 'var_index'])\n",
    "             .apply(lambda x: x.str.split(',').explode())\n",
    "             .reset_index())\n",
    "\n",
    "    g = variants.groupby(['var_index'])\n",
    "    variants.loc[g['var_index'].transform('size').gt(1),\n",
    "           'var_index'] += '-'+g.cumcount().astype(str)\n",
    "    \n",
    "variant_scores = pd.DataFrame({'var_index':variants.var_index})\n",
    "    \n",
    "  \n",
    "\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "# Filter out variants that cannot be scored\n",
    "\n",
    "# Get indexes for variants to exclude\n",
    "\n",
    "# Exclude mitochondrial variants\n",
    "chrM_var = pd.DataFrame({'var_index' : list(variants[variants.CHROM == 'chrM'].var_index),\n",
    "                         'reason' : ' Mitochondrial chromosome.'})\n",
    "\n",
    "# Exclude variants larger than limit\n",
    "if 'SVLEN' in variants.columns:\n",
    "    too_long_var = pd.DataFrame({'var_index' : [y for x,y in zip(variants.SVLEN, variants.var_index) \n",
    "                                                if not pd.isnull(x) and abs(int(x)) > svlen_limit],\n",
    "                                 'reason' : f' SV longer than {svlen_limit}.'})\n",
    "    unsuitable_var = pd.DataFrame({'var_index' : [y for x,y,z in zip(variants.SVTYPE, variants.var_index, variants.ALT) \n",
    "                                                  if not pd.isnull(x) and \n",
    "                                                  x not in [\"DEL\", \"DUP\", \"INV\", \"BND\"] and \n",
    "                                                  all([g not in nt for g in z])],\n",
    "                                   'reason' : ' SV type not compatible.'})\n",
    "else:\n",
    "    too_long_var = pd.DataFrame()\n",
    "    unsuitable_var = pd.DataFrame()\n",
    "\n",
    "filtered_out = pd.concat([chrM_var, too_long_var], axis = 0)\n",
    "filtered_out = pd.concat([filtered_out, unsuitable_var], axis = 0)\n",
    "filtered_out.var_index = filtered_out.var_index.astype('str')\n",
    "\n",
    "# Exclude\n",
    "variants = variants[[x not in filtered_out.var_index.values for x in variants.var_index]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "547d077b-4327-4c66-9128-a46764ac02f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "SV_types = ['DEL', 'DUP', 'BND', 'INV']\n",
    "\n",
    "Kaivola2023 = pd.read_csv('Kaivola2023_Manta_SVs.txt', sep = '\\t')\n",
    "Kaivola2023 = Kaivola2023[abs(Kaivola2023.SVLEN) < 500000]\n",
    "Kaivola2023['CHROM'] = 'chr' + Kaivola2023['CHROM']\n",
    "Kaivola2023 = Kaivola2023[Kaivola2023.Algorithms == 'manta']\n",
    "Kaivola2023 = Kaivola2023[[x in SV_types for x in Kaivola2023.SVTYPE]]\n",
    "# Kaivola2023 = Kaivola2023[Kaivola2023.Filter == 'PASS']\n",
    "\n",
    "Kaivola2023_subset = pd.DataFrame()\n",
    "for SVTYPE in SV_types:\n",
    "    Kaivola2023_subset = pd.concat([Kaivola2023_subset,\n",
    "                                    Kaivola2023.loc[random.sample(list(Kaivola2023[Kaivola2023.SVTYPE == SVTYPE].index), 10)]],\n",
    "                                    axis = 0)\n",
    "\n",
    "Kaivola2023_subset.to_csv('Kaivola2023_subset.txt', sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e15ac04d-d08d-43f5-b22a-a043a4ef6377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a specific variant\n",
    "\n",
    "i = 0\n",
    "shift = 0 \n",
    "revcomp = False\n",
    "get_tracks = True\n",
    "get_maps = True\n",
    "\n",
    "variant = variants.iloc[i]\n",
    "\n",
    "var_index = variant.var_index\n",
    "CHR = variant.CHROM\n",
    "POS = variant.POS\n",
    "REF = variant.REF\n",
    "ALT = variant.ALT\n",
    "\n",
    "if 'SVTYPE' in variants.columns:\n",
    "    END = variant.END\n",
    "    SVTYPE = variant.SVTYPE\n",
    "    SVLEN = variant.SVLEN\n",
    "else:\n",
    "    END = np.nan\n",
    "    SVTYPE = np.nan\n",
    "    SVLEN = 0\n",
    "\n",
    "\n",
    "# Create sequences_i from variant input\n",
    "sequences_i = get_seq_utils.get_sequences_SV(CHR, POS, REF, ALT, END, SVTYPE, shift, revcomp)\n",
    "    \n",
    "\n",
    "scores = get_Akita_scores_utils.get_scores(POS, SVTYPE, SVLEN, \n",
    "                                           sequences_i, scores_to_use, \n",
    "                                           shift, revcomp, \n",
    "                                           get_tracks, get_maps, Akita_cell_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b685c318-5557-4d68-b576-5254e9c28323",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = 'weighted_ATAC/SuPreMo'\n",
    "# out_file = 'test/tumor.illumina.manta.EA_T_1_top'\n",
    "\n",
    "scores = pd.read_csv(f'{out_file}_scores', sep = '\\t')\n",
    "# maps = np.load(f'{out_file}_maps.npy', allow_pickle=\"TRUE\").item()\n",
    "# tracks = np.load(f'{out_file}_tracks.npy', allow_pickle=\"TRUE\").item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8866a601-2498-4289-9deb-a09874ce108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = pd.read_csv('Kaivola2023_subset-Copy1.txt', sep = '\\t')\n",
    "# variants = pd.read_csv('test_data/example_application/tumor.illumina.manta.EA_T_1_top.txt', sep = '\\t')\n",
    "\n",
    "i = 0 #8\n",
    "shift = 0 \n",
    "revcomp = False\n",
    "get_tracks = True\n",
    "get_maps = True\n",
    "\n",
    "variant = variants.iloc[i]\n",
    "\n",
    "# var_index = variant.var_index\n",
    "CHR = variant.CHROM\n",
    "POS = variant.POS\n",
    "REF = variant.REF\n",
    "ALT = variant.ALT\n",
    "\n",
    "if 'SVTYPE' in variants.columns:\n",
    "    END = variant.END\n",
    "    SVTYPE = variant.SVTYPE\n",
    "    SVLEN = variant.SVLEN\n",
    "else:\n",
    "    END = np.nan\n",
    "    SVTYPE = np.nan\n",
    "    SVLEN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1c2a823-14f3-42ed-8a53-86d12386a5e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m use_roi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      4\u001b[0m sequences_i \u001b[38;5;241m=\u001b[39m get_seq_utils\u001b[38;5;241m.\u001b[39mget_sequences_SV(CHR, POS, REF, ALT, END, SVTYPE, shift, revcomp)\n\u001b[0;32m----> 6\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mget_Akita_scores_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCHR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPOS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSVTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSVLEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43msequences_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores_to_use\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mshift\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevcomp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mget_tracks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_maps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_roi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAkita_cell_types\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SuPreMo/scripts/get_Akita_scores_utils.py:687\u001b[0m, in \u001b[0;36mget_scores\u001b[0;34m(CHR, POS, SVTYPE, SVLEN, sequences, scores, shift, revcomp, get_tracks, get_maps, use_roi, Akita_cell_types)\u001b[0m\n\u001b[1;32m    683\u001b[0m disruption_track \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(scoring_map_methods(matrices[\u001b[38;5;241m0\u001b[39m], matrices[\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_track\u001b[39m\u001b[38;5;124m'\u001b[39m)()\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_roi:\n\u001b[0;32m--> 687\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mroi_weights\u001b[49m:\n\u001b[1;32m    688\u001b[0m         roi_weights\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "Akita_cell_types = ['H1hESC']\n",
    "use_roi = True\n",
    "\n",
    "sequences_i = get_seq_utils.get_sequences_SV(CHR, POS, REF, ALT, END, SVTYPE, shift, revcomp)\n",
    "\n",
    "scores = get_Akita_scores_utils.get_scores(CHR, POS, SVTYPE, SVLEN, \n",
    "                                           sequences_i, scores_to_use, \n",
    "                                           shift, revcomp, \n",
    "                                           get_tracks, get_maps, use_roi, Akita_cell_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9fe24cc1-8d92-4cf3-b47f-dcbe2bb95e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type = 'H1hESC'\n",
    "\n",
    "# scores = scores[~np.isnan(scores[f'mse_0.5-weighted_{cell_type}_0'])]\n",
    "scores['mse_diff'] = [x-y for x,y in zip(scores[f'mse_0.5-weighted_{cell_type}_0'], scores[f'mse_{cell_type}_0'])]\n",
    "scores['corr_diff'] = [x-y for x,y in zip(scores[f'corr_0.5-weighted_{cell_type}_0'], scores[f'corr_unweighted_{cell_type}_0'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e62e8259-ff1a-4ab0-a9d8-e5f1959b2a5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_index</th>\n",
       "      <th>mse_H1hESC_0</th>\n",
       "      <th>mse_0.5-weighted_H1hESC_0</th>\n",
       "      <th>mse_1.0-weighted_H1hESC_0</th>\n",
       "      <th>corr_H1hESC_0</th>\n",
       "      <th>corr_unweighted_H1hESC_0</th>\n",
       "      <th>corr_0.5-weighted_H1hESC_0</th>\n",
       "      <th>corr_1.0-weighted_H1hESC_0</th>\n",
       "      <th>mse_diff</th>\n",
       "      <th>corr_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.005778</td>\n",
       "      <td>0.005302</td>\n",
       "      <td>0.006015</td>\n",
       "      <td>0.977479</td>\n",
       "      <td>0.029743</td>\n",
       "      <td>0.027299</td>\n",
       "      <td>0.030960</td>\n",
       "      <td>-4.756945e-04</td>\n",
       "      <td>-0.002444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.990907</td>\n",
       "      <td>0.019540</td>\n",
       "      <td>0.019114</td>\n",
       "      <td>0.019657</td>\n",
       "      <td>-1.031259e-04</td>\n",
       "      <td>-0.000425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.003794</td>\n",
       "      <td>0.003794</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.968760</td>\n",
       "      <td>0.046211</td>\n",
       "      <td>0.046211</td>\n",
       "      <td>0.043544</td>\n",
       "      <td>-1.161007e-08</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.990093</td>\n",
       "      <td>0.013379</td>\n",
       "      <td>0.013379</td>\n",
       "      <td>0.013437</td>\n",
       "      <td>-7.426196e-10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>0.983361</td>\n",
       "      <td>0.022739</td>\n",
       "      <td>0.022739</td>\n",
       "      <td>0.022491</td>\n",
       "      <td>2.121796e-08</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>0.003080</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.991904</td>\n",
       "      <td>0.013133</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.012717</td>\n",
       "      <td>9.288844e-05</td>\n",
       "      <td>0.000539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.007234</td>\n",
       "      <td>0.007541</td>\n",
       "      <td>0.007111</td>\n",
       "      <td>0.952204</td>\n",
       "      <td>0.054048</td>\n",
       "      <td>0.055520</td>\n",
       "      <td>0.053459</td>\n",
       "      <td>3.076816e-04</td>\n",
       "      <td>0.001472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.009214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968486</td>\n",
       "      <td>0.037286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.009705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.962273</td>\n",
       "      <td>0.042723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.003925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990873</td>\n",
       "      <td>0.011354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.009161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.544916</td>\n",
       "      <td>0.450909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.006680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.974754</td>\n",
       "      <td>0.036526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.005926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.983551</td>\n",
       "      <td>0.022849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.009848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.963581</td>\n",
       "      <td>0.054099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    var_index  mse_H1hESC_0  mse_0.5-weighted_H1hESC_0  \\\n",
       "0           0      0.005778                   0.005302   \n",
       "1           1      0.001603                   0.001500   \n",
       "4           4      0.003794                   0.003794   \n",
       "12         12      0.002012                   0.002012   \n",
       "9           9      0.004432                   0.004432   \n",
       "6           6      0.002987                   0.003080   \n",
       "10         10      0.007234                   0.007541   \n",
       "2           2      0.009214                        NaN   \n",
       "3           3      0.009705                        NaN   \n",
       "5           5      0.003925                        NaN   \n",
       "7           7      0.009161                        NaN   \n",
       "8           8      0.006680                        NaN   \n",
       "11         11      0.005926                        NaN   \n",
       "13         13      0.009848                        NaN   \n",
       "\n",
       "    mse_1.0-weighted_H1hESC_0  corr_H1hESC_0  corr_unweighted_H1hESC_0  \\\n",
       "0                    0.006015       0.977479                  0.029743   \n",
       "1                    0.001632       0.990907                  0.019540   \n",
       "4                    0.003632       0.968760                  0.046211   \n",
       "12                   0.002016       0.990093                  0.013379   \n",
       "9                    0.004420       0.983361                  0.022739   \n",
       "6                    0.002915       0.991904                  0.013133   \n",
       "10                   0.007111       0.952204                  0.054048   \n",
       "2                         NaN       0.968486                  0.037286   \n",
       "3                         NaN       0.962273                  0.042723   \n",
       "5                         NaN       0.990873                  0.011354   \n",
       "7                         NaN       0.544916                  0.450909   \n",
       "8                         NaN       0.974754                  0.036526   \n",
       "11                        NaN       0.983551                  0.022849   \n",
       "13                        NaN       0.963581                  0.054099   \n",
       "\n",
       "    corr_0.5-weighted_H1hESC_0  corr_1.0-weighted_H1hESC_0      mse_diff  \\\n",
       "0                     0.027299                    0.030960 -4.756945e-04   \n",
       "1                     0.019114                    0.019657 -1.031259e-04   \n",
       "4                     0.046211                    0.043544 -1.161007e-08   \n",
       "12                    0.013379                    0.013437 -7.426196e-10   \n",
       "9                     0.022739                    0.022491  2.121796e-08   \n",
       "6                     0.013672                    0.012717  9.288844e-05   \n",
       "10                    0.055520                    0.053459  3.076816e-04   \n",
       "2                          NaN                         NaN           NaN   \n",
       "3                          NaN                         NaN           NaN   \n",
       "5                          NaN                         NaN           NaN   \n",
       "7                          NaN                         NaN           NaN   \n",
       "8                          NaN                         NaN           NaN   \n",
       "11                         NaN                         NaN           NaN   \n",
       "13                         NaN                         NaN           NaN   \n",
       "\n",
       "    corr_diff  \n",
       "0   -0.002444  \n",
       "1   -0.000425  \n",
       "4    0.000000  \n",
       "12   0.000000  \n",
       "9    0.000000  \n",
       "6    0.000539  \n",
       "10   0.001472  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "5         NaN  \n",
       "7         NaN  \n",
       "8         NaN  \n",
       "11        NaN  \n",
       "13        NaN  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.sort_values('mse_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb8909d7-3187-433a-8d0a-77602f1978d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cooltools.lib.plotting import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.preprocessing import normalize\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd5159b0-dd90-4c5d-a180-4f455036d5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.font_manager:findfont: Font family 'Helvetica' not found.\n",
      "WARNING:matplotlib.font_manager:findfont: Font family 'Helvetica' not found.\n",
      "WARNING:matplotlib.font_manager:findfont: Font family 'Helvetica' not found.\n",
      "WARNING:matplotlib.font_manager:findfont: Font family 'Helvetica' not found.\n",
      "WARNING:matplotlib.font_manager:findfont: Font family 'Helvetica' not found.\n",
      "WARNING:matplotlib.font_manager:findfont: Font family 'Helvetica' not found.\n",
      "WARNING:matplotlib.font_manager:findfont: Font family 'Helvetica' not found.\n",
      "WARNING:matplotlib.font_manager:findfont: Font family 'Helvetica' not found.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "\n",
    "plt.hist(scores[f'mse_{cell_type}_0'].values, color = 'gray', alpha = 0.5, label = '0', bins = 10)\n",
    "plt.hist(scores[f'mse_0.5-weighted_{cell_type}_0'].values, color = 'blue', alpha = 0.5, label = '0.5', bins = 10)\n",
    "plt.hist(scores[f'mse_1.0-weighted_{cell_type}_0'].values, color = 'red', alpha = 0.5, label = '1', bins = 10)\n",
    "    \n",
    "plt.legend(loc = 'upper left', fontsize = 10)\n",
    "plt.xlabel('Disruption score', fontname = 'Helvetica', size = 12)\n",
    "plt.ylabel('Variant count', fontname = 'Helvetica', size = 12)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8900725-edea-4ef9-a014-f98706a9ade6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.font_manager:findfont: Font family 'Helvetica' not found.\n",
      "WARNING:matplotlib.font_manager:findfont: Font family 'Helvetica' not found.\n",
      "WARNING:matplotlib.font_manager:findfont: Font family 'Helvetica' not found.\n",
      "WARNING:matplotlib.font_manager:findfont: Font family 'Helvetica' not found.\n",
      "WARNING:matplotlib.font_manager:findfont: Font family 'Helvetica' not found.\n",
      "WARNING:matplotlib.font_manager:findfont: Font family 'Helvetica' not found.\n",
      "WARNING:matplotlib.font_manager:findfont: Font family 'Helvetica' not found.\n",
      "WARNING:matplotlib.font_manager:findfont: Font family 'Helvetica' not found.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "\n",
    "plt.hist(1- scores[f'corr_{cell_type}_0'].values, color = 'gray', alpha = 0.5, label = '0', bins = 10)\n",
    "plt.hist(1- scores[f'corr_0.5-weighted_{cell_type}_0'].values, color = 'blue', alpha = 0.5, label = '0.5', bins = 10)\n",
    "plt.hist(1- scores[f'corr_1.0-weighted_{cell_type}_0'].values, color = 'red', alpha = 0.5, label = '1', bins = 10)\n",
    "    \n",
    "plt.legend(loc = 'upper left', fontsize = 10)\n",
    "plt.xlabel('Disruption score', fontname = 'Helvetica', size = 12)\n",
    "plt.ylabel('Variant count', fontname = 'Helvetica', size = 12)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a14c53a-0b52-4c8c-bede-5da5dcec59ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d963c84c-8acb-4ae8-83b9-0cf46867da63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec7580f-d57f-4cf4-8c29-02f28989a428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c4e4e3-e7c0-48f5-a5d6-fbe19ac59995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2b1d3a-a49a-46cb-85c3-2af8ccf18b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0105aa9-de55-4d0e-ab07-1eaf2f77b80b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
